{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kallviktor/RandomInterpolationGAN/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C12B_Jtthu2r"
   },
   "source": [
    "https://github.com/kmualim/DCGAN-Keras-Implementation/blob/master/dcgan-mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phK8FR8Vfwlq",
    "outputId": "90b84d18-0842-48c1-d9af-bf9c122734c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 390,785\n",
      "Trainable params: 389,825\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Start\n",
      " Epoch:1, G_loss: 0.6675716638565063, D_loss:1.25387504696846\n",
      "[[-0.23773507 -1.39927919 -0.70023097 ...  0.70571523 -0.09913171\n",
      "  -0.52815388]\n",
      " [ 0.53222557  1.59774856 -0.57740021 ... -1.39464909  0.6720858\n",
      "  -0.06471741]\n",
      " [-0.60657639  0.51139502 -1.14267188 ...  0.27482481  0.21761539\n",
      "   0.97777439]\n",
      " ...\n",
      " [ 0.5404133   0.45343138  0.87832793 ... -0.17799168  0.99025536\n",
      "   0.17316119]\n",
      " [-0.37402039  1.63945462  0.33732221 ...  0.85373148  1.99168641\n",
      "  -0.16059959]\n",
      " [ 1.31920911 -0.83807319 -0.60499479 ... -0.35886524  3.14137672\n",
      "   1.38230197]]\n",
      "(25, 100)\n",
      " Epoch:2, G_loss: 0.6395540833473206, D_loss:0.8627902865409851\n",
      " Epoch:3, G_loss: 0.637485921382904, D_loss:0.833116352558136\n",
      "[[ 1.1461316  -0.35114314 -0.92097686 ...  0.54098247 -0.74516577\n",
      "  -0.33370055]\n",
      " [ 0.29408739 -0.20061634 -1.10303028 ...  0.78992649  0.67818552\n",
      "   0.21972503]\n",
      " [ 1.19566889 -1.28019139 -1.02588469 ... -0.59557202  0.09190367\n",
      "   1.1594921 ]\n",
      " ...\n",
      " [-0.596497   -1.1530905  -1.05899433 ... -0.00187205 -0.7486093\n",
      "   0.35228536]\n",
      " [-0.40028275  0.64505856  0.61776378 ...  1.62739063  0.58246949\n",
      "  -0.95991111]\n",
      " [-1.74867569  1.11603691  1.47506017 ... -0.05424308 -1.07131207\n",
      "  -1.67456606]]\n",
      "(25, 100)\n",
      " Epoch:4, G_loss: 0.6238594055175781, D_loss:0.7315248847007751\n",
      " Epoch:5, G_loss: 0.6204572916030884, D_loss:0.6837593019008636\n",
      "[[ 0.85837072  1.77405116 -0.89002924 ... -1.3514237  -1.26368365\n",
      "   0.97404573]\n",
      " [-1.99499743 -0.51511655  0.50617132 ... -0.80930149  0.64619882\n",
      "   0.16945982]\n",
      " [ 0.81652484 -0.41099806  1.22868963 ...  0.55154336  1.68042742\n",
      "   0.56307166]\n",
      " ...\n",
      " [-1.62148168  0.88538953 -2.0089281  ...  2.17323796 -0.68093486\n",
      "  -0.12801748]\n",
      " [-0.79022051  0.242939    2.08933447 ...  0.14020424  1.1295858\n",
      "   2.18986913]\n",
      " [ 0.49877537  0.31156986 -0.50239055 ... -0.54174611  0.08527318\n",
      "   0.84564751]]\n",
      "(25, 100)\n",
      " Epoch:6, G_loss: 0.6316612958908081, D_loss:0.777868390083313\n",
      " Epoch:7, G_loss: 0.6247224807739258, D_loss:0.442220538854599\n",
      "[[ 0.56027259 -1.05608909 -0.15169999 ...  0.34769556  1.29700925\n",
      "   1.14776956]\n",
      " [ 0.68320946 -0.68447478 -1.06104613 ...  0.6763039   0.21044278\n",
      "  -2.0087669 ]\n",
      " [-0.41614954  0.89476731 -0.36739843 ... -0.30310106 -1.80600644\n",
      "  -0.97347341]\n",
      " ...\n",
      " [ 1.23288739  1.9781243   2.01050886 ... -0.41666545  0.27929663\n",
      "   0.72560407]\n",
      " [-0.70925448 -0.05143833  0.89934144 ... -1.4658342   0.15312714\n",
      "   0.44178678]\n",
      " [-0.07051402  1.02369525  0.40025307 ... -0.29726373 -0.41711604\n",
      "  -1.18889434]]\n",
      "(25, 100)\n",
      " Epoch:8, G_loss: 0.6376129984855652, D_loss:0.5294959545135498\n",
      " Epoch:9, G_loss: 0.6560872793197632, D_loss:0.4086850583553314\n",
      "[[ 1.0430817  -0.29497221  0.64501039 ... -2.19654166 -0.30517531\n",
      "   0.1019264 ]\n",
      " [ 0.40217536 -0.26943765  2.13895348 ...  1.44982951 -0.52350815\n",
      "   0.65341023]\n",
      " [-1.35672465  0.91575915  0.29654687 ...  0.14222736  0.32641714\n",
      "   1.10907995]\n",
      " ...\n",
      " [-1.27775261 -0.89733485 -1.13259438 ...  0.36898953 -0.57015374\n",
      "  -0.21278084]\n",
      " [-0.49782656 -0.80769731 -1.36667895 ... -0.17704281 -1.01457824\n",
      "   0.35337244]\n",
      " [ 0.48859905  0.33592571  0.51745052 ... -0.22824775 -0.0740223\n",
      "  -0.7045997 ]]\n",
      "(25, 100)\n",
      " Epoch:10, G_loss: 0.6295615434646606, D_loss:0.4676450788974762\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape \n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D \n",
    "from keras.layers import LeakyReLU, Dropout \n",
    "from keras.layers import BatchNormalization \n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.initializers import RandomNormal, Zeros\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt \n",
    "import sys \n",
    "import numpy as np\n",
    "\n",
    "class GAN(object): \n",
    "    def __init__(self):\n",
    "      self.img_rows = 28 \n",
    "      self.img_cols = 28 \n",
    "      self.channel=1\n",
    "      self.img_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "      \n",
    "      optimizer = Adam(0.0002, 0.5)\n",
    "     \n",
    "    def build_discriminator(self):\n",
    "      model = Sequential()\n",
    "      depth = 32 \n",
    "      dropout=0.25 \n",
    "      input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "      \n",
    "      model.add(Conv2D(depth*1, 3, strides=2, input_shape=input_shape, padding='same', kernel_initializer='random_uniform'))\n",
    "      model.add(BatchNormalization(momentum=0.9))\n",
    "      model.add(LeakyReLU(alpha=0.2))\n",
    "      model.add(Dropout(dropout))\n",
    "      model.add(Conv2D(depth*2, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\n",
    "      model.add(BatchNormalization(momentum=0.9))\n",
    "      model.add(LeakyReLU(alpha=0.2))\n",
    "      model.add(Dropout(dropout))\n",
    "      model.add(Conv2D(depth*4, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\n",
    "      model.add(BatchNormalization(momentum=0.9))\n",
    "      model.add(LeakyReLU(alpha=0.2))\n",
    "      model.add(Dropout(dropout))\n",
    "      model.add(Conv2D(depth*8, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\n",
    "      model.add(BatchNormalization(momentum=0.9))\n",
    "      model.add(LeakyReLU(alpha=0.2))\n",
    "      model.add(Dropout(dropout))\n",
    "\n",
    "      # Each MNIST input = 28 X 28 X 1, depth = 1\n",
    "      # Each Output = 14 X 14 X 1, depth = 64 \n",
    "      # Model has 4 convolutional layer, each with a dropout layer in between \n",
    "\n",
    "      # Output \n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(1))\n",
    "      model.add(Activation('sigmoid'))\n",
    "      model.summary()\n",
    "      \n",
    "      img = Input(shape=(self.img_shape))\n",
    "      validity = model(img)\n",
    "      \n",
    "      return Model(img, validity) \n",
    "\n",
    "    # generator takes noise as input and generates imgs\n",
    "                \n",
    "    def build_generator(self):\n",
    "      generator = Sequential() \n",
    "      dropout = 0.4 \n",
    "      depth = 128\n",
    "      dim = 7\n",
    "\n",
    "      # In: 100 \n",
    "      # Out: dim X dim X depth \n",
    "\n",
    "      generator.add(Dense(dim*dim*depth, input_dim=100))\n",
    "      generator.add(Activation('relu'))\n",
    "      generator.add(Reshape((dim, dim, depth)))\n",
    "      generator.add(UpSampling2D())\n",
    "      #generator.add(Dropout(dropout))\n",
    "\n",
    "      # In: dim X dim X depth\n",
    "      # Out: 2*dim X 2*dim X depth/2 \n",
    "\n",
    "      generator.add(Conv2D(depth, 3, padding='same'))\n",
    "      generator.add(BatchNormalization(momentum=0.9))\n",
    "      generator.add(Activation('relu'))\n",
    "      generator.add(UpSampling2D())\n",
    "      generator.add(Conv2D(int(depth/2), 3, padding='same'))\n",
    "      generator.add(BatchNormalization(momentum=0.9))\n",
    "      generator.add(Activation('relu'))\n",
    "     \n",
    "\n",
    "      # Out : 28 X 28 X 1 grayscale image [0.0, 1.0] per pix\n",
    "      generator.add(Conv2D(1,3,padding='same'))\n",
    "      generator.add(Activation('tanh'))\n",
    "      generator.summary()\n",
    "      \n",
    "      noise = Input(shape=(100,))\n",
    "      img = generator(noise)\n",
    "      \n",
    "      return Model(noise, img)\n",
    "    \n",
    "    # Build and compile discriminator\n",
    "    def DM(self):\n",
    "      optimizer = Adam(0.0002, 0.5)\n",
    "      DM = self.build_discriminator()\n",
    "      DM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "      return DM    \n",
    "\n",
    "class dcgan(object):\n",
    "  def __init__(self):\n",
    "    self.img_rows=28\n",
    "    self.img_cols=28\n",
    "    self.channels=1\n",
    "\n",
    "    # building the generator \n",
    "    self.GAN = GAN()\n",
    "    self.DM = self.GAN.DM()\n",
    "    self.generator = self.GAN.build_generator()\n",
    "\n",
    "\n",
    "    z = Input(shape=(100,))\n",
    "    img = self.generator(z)\n",
    "    self.DM.trainable = False\n",
    "    valid = self.DM(img)\n",
    "    \n",
    "    self.combined = Model(z, valid)\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    # training input \n",
    "    # To change dataset, place dataset below \n",
    "    (self.x_train, _), (_,_) = mnist.load_data()\n",
    "    self.x_train = self.x_train/127.5 -1.\n",
    "    self.x_train = np.expand_dims(self.x_train, axis=3) \n",
    "    #x_train = x_train/127.5 -1. \n",
    "    #x_train = np.expand_dims(x_train, axis=3)\n",
    "    self.n_samples = 25\n",
    "    self.noise_dim = 100\n",
    "  \n",
    "  # method to generate noise \n",
    "  def gennoise(self,batch_size, noise_dim): \n",
    "   \tx = np.random.normal(0, 1.0, (batch_size, self.noise_dim))\n",
    "   \treturn x\n",
    "\n",
    "  def plt_imgs(self,epoch): \n",
    "    noise = self.gennoise(self.n_samples, self.noise_dim)\n",
    "    print(noise)\n",
    "    print(noise.shape)\n",
    "    fake_imgs = self.generator.predict(noise)\n",
    "    fake_imgs = 0.5 * fake_imgs + 0.5\n",
    "  \n",
    "    fig,axs = plt.subplots(5,5)\n",
    "    count = 0 \n",
    "    for i in range(5): \n",
    "        for j in range(5): \n",
    "          axs[i,j].imshow(fake_imgs[count, :, :, 0], cmap='gray')\n",
    "          axs[i,j].axis('off')\n",
    "          count+=1\n",
    "      \n",
    "    fig.savefig(\"mnist_%d.png\" % epoch)\n",
    "    plt.close()\n",
    "  \n",
    "  \n",
    "  def train(self,n_epochs, batch_size):\n",
    "    train_hist={}\n",
    "    train_hist['D_losses']=[]\n",
    "    train_hist['G_losses']=[]\n",
    "    print(\"Start\")\n",
    "    true_labels=np.ones((batch_size,1))\n",
    "    gen_gene_labels=np.zeros((batch_size,1))\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "      index = np.random.randint(0, self.x_train.shape[0], batch_size)\n",
    "      images = self.x_train[index]\n",
    "      \n",
    "      noise_data = self.gennoise(batch_size, 100)\n",
    "      gen_imgs = self.generator.predict(noise_data)\n",
    "      \n",
    "      \n",
    "      d_loss = self.DM.train_on_batch(images, true_labels)\n",
    "    \n",
    "      d_loss_generated = self.DM.train_on_batch(gen_imgs, gen_gene_labels)\n",
    "      \n",
    "      total_d_loss = 0.5 * np.add(d_loss, d_loss_generated)\n",
    "      \n",
    "      train_hist['D_losses'].append(total_d_loss[0])\n",
    "        \n",
    "      noise_data = self.gennoise(batch_size, 100)\n",
    "      y1 = np.ones((batch_size, 1))    \n",
    "      \n",
    "      g_loss = self.combined.train_on_batch(noise_data, y1)\n",
    "\n",
    "      train_hist['G_losses'].append(g_loss)\n",
    "      print (' Epoch:{}, G_loss: {}, D_loss:{}'.format(epoch+1, g_loss, total_d_loss[0]))\n",
    "      \n",
    "      #if epoch%50==0:\n",
    "      if epoch%2 == 0:\n",
    "        self.plt_imgs(epoch)\n",
    "      \n",
    "    return train_hist\n",
    "  \n",
    "  def plotting_imgs(self,epoch): \n",
    "      noise = self.gennoise(25,100)\n",
    "      print(noise)\n",
    "      noise.shape()\n",
    "      fake_imgs = self.generator.predict(noise)\n",
    "      fake_imgs = 0.5 * fake_imgs + 0.5\n",
    "    \n",
    "      fig,axs = plt.subplots(5,5)\n",
    "      count = 0 \n",
    "      for i in range(5): \n",
    "        for j in range(5): \n",
    "          axs[i,j].imshow(fake_imgs[count, :, :, 0], cmap='gray')\n",
    "          axs[i,j].axis('off')\n",
    "          count+=1\n",
    "\n",
    "#if __name__ == '__main__': \n",
    "mnist_dcgan = dcgan()\n",
    "train_hist = mnist_dcgan.train(10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hutkmn9C9byL",
    "outputId": "ca8f6923-92d2-40a9-b71f-c9a9f0b30f20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = mnist_dcgan.gennoise(1,100)\n",
    "#z.shape\n",
    "x = mnist_dcgan.generator.predict(z)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xfL5s_SkA24i"
   },
   "outputs": [],
   "source": [
    "def ker(h, a=1, b=1):\n",
    "  return np.exp(-b*np.abs(h)**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OKUdfnf2BSqj"
   },
   "outputs": [],
   "source": [
    "def muhat(t, z0, zT, T=1):\n",
    "  num = z0*(ker(t) - ker(T-t)*ker(T)) + zT*(ker(T-t) - ker(t)*ker(T))\n",
    "  denom = 1 - ker(T)**2\n",
    "  return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nmnOziYwCQut"
   },
   "outputs": [],
   "source": [
    "def khat(t, s, T=1):\n",
    "  T1 = ker(t-s)\n",
    "  num = ker(T)*(ker(T-s)*ker(t) + ker(s)*ker(T-t)) - ker(T-s)*ker(T-t) - ker(s)*ker(t)\n",
    "  denom = 1 - ker(T)**2\n",
    "  T2 = num/denom\n",
    "  return T1 + T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YqG_GjAsDbsw"
   },
   "outputs": [],
   "source": [
    "def BP(z0, zT, T, N):\n",
    "  # Bridge process from z0 to zT in N steps (over time-dimension) and in time T\n",
    "  \n",
    "  t_grid = np.linspace(0, T, N)    # Uniform grid on t-axis\n",
    "\n",
    "  # For each coordinate of z0 and zT we simulate a bridge-process\n",
    "\n",
    "  dim = len(z0)\n",
    "  Z = np.zeros((dim,N))\n",
    "\n",
    "  for (i, z0_i, zT_i) in zip(range(dim), z0, zT):\n",
    "    mean_i = np.zeros(N)    # mean.shape --> (N,) i.e. a column vector of length N\n",
    "    for k in range(N):\n",
    "      t = t_grid[k]\n",
    "      mean_i[k] = muhat(t, z0_i, zT_i)\n",
    "    \n",
    "    cov_i = np.zeros((N,N))\n",
    "    for m in range(N):\n",
    "      t = t_grid[m]\n",
    "      for n in range(N):\n",
    "        s = t_grid[n]\n",
    "        cov_i[m][n] = khat(t, s)\n",
    "    \n",
    "    Z_i = np.random.multivariate_normal(mean_i, cov_i)\n",
    "    Z[i][:] = Z_i\n",
    "  Z.shape\n",
    "  return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vNrycBY35iS",
    "outputId": "4516fa4e-a17a-4a7f-dd69-811967824f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage finished: 0%\n",
      "Percentage finished: 10%\n",
      "Percentage finished: 20%\n",
      "Percentage finished: 30%\n",
      "Percentage finished: 40%\n",
      "Percentage finished: 50%\n",
      "Percentage finished: 60%\n",
      "Percentage finished: 70%\n",
      "Percentage finished: 80%\n",
      "Percentage finished: 90%\n",
      "Percentage finished: 100%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "z0 = np.zeros(100)    # z0.shape --> (100,)\n",
    "zT = np.ones(100)   # zT.shape --> (100,)\n",
    "\n",
    "dim = len(z0)\n",
    "T = 1\n",
    "N = 10    # Number of steps of random walk / sample of process in t-dimension (time-dimension)\n",
    "batch = 100\n",
    "\n",
    "samples = np.zeros(shape=(dim,N,batch))\n",
    "pr = 0\n",
    "for i in range(batch):\n",
    "  samples[:,:,i] = BP(z0, zT, T, N)\n",
    "  if (i/batch) >= pr:\n",
    "    percent = round(pr*100)\n",
    "    pr += 0.1\n",
    "    print('Percentage finished: {}%'.format(percent))\n",
    "print('Percentage finished: 100%')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "C4cSjP_bCdP2"
   },
   "outputs": [],
   "source": [
    "def gen_particles(z0, zT, T, N, batch_size):\n",
    "  samples = np.zeros(shape=(dim,N,batch_size))\n",
    "  pr = 0\n",
    "  for i in range(batch_size):\n",
    "    samples[:,:,i] = BP(z0, zT, T, N)\n",
    "    if (i/batch_size) >= pr:\n",
    "      percent = round(pr*100)\n",
    "      pr += 0.1\n",
    "      print('Percentage finished: {}%'.format(percent))\n",
    "  print('Percentage finished: 100%')\n",
    "  print('Done!')\n",
    "\n",
    "  return samples[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m--MIcdTIejb"
   },
   "outputs": [],
   "source": [
    "def weight_func(z, G, D):\n",
    "  x = G(z)\n",
    "  weight = D(x)/(1 - D(x))\n",
    "  return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rxDKztyfD2Dg",
    "outputId": "0671404b-63e5-4f03-d2c7-fcce3fd8f024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage finished: 0%\n",
      "Percentage finished: 10%\n",
      "Percentage finished: 20%\n",
      "Percentage finished: 30%\n",
      "Percentage finished: 40%\n",
      "Percentage finished: 50%\n",
      "Percentage finished: 60%\n",
      "Percentage finished: 70%\n",
      "Percentage finished: 80%\n",
      "Percentage finished: 100%\n",
      "Done!\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5f03a099ce23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-94a7bff633de>\u001b[0m in \u001b[0;36mweight_func\u001b[0;34m(z, G, D)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweight_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:425 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 100 but received input with shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "z0 = np.zeros(100)    # z0.shape --> (100,)\n",
    "zT = np.ones(100)   # zT.shape --> (100,)\n",
    "\n",
    "dim = len(z0)\n",
    "T = 1\n",
    "N = 10    # Number of steps of random walk / sample of process in t-dimension (time-dimension)\n",
    "\n",
    "n = 10\n",
    "parts = np.zeros((dim,n))\n",
    "paths = np.zeros((dim,N,n))\n",
    "paths[:,0,:] = np.full((dim,n),z0[np.newaxis].T)\n",
    "paths[:,-1,:] = np.full((dim,n),zT[np.newaxis].T)\n",
    "\n",
    "S = range(n)    # Set of indices, just in resampling step below\n",
    "\n",
    "G = mnist_dcgan.generator.predict\n",
    "D = mnist_dcgan.DM.predict\n",
    "\n",
    "for step in range(N):\n",
    "  parts = gen_particles(z0, zT, T, N, n)\n",
    "  weights = np.zeros(n)\n",
    "  for k in range(n):\n",
    "    z = parts[k,:]\n",
    "    w = weight_func(z, G, D)\n",
    "    weights[k] = w\n",
    "  \n",
    "  # Resampling\n",
    "  S_re = np.random.choice(S, replace=True, p=weights)\n",
    "  parts = parts[S_re]\n",
    "\n",
    "  # Save steps taken\n",
    "  paths[:,step+1,:] = parts\n",
    "\n",
    "  z0 = parts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBFIN4xnLqCo",
    "outputId": "ba19c6de-b454-4807-99ea-4ca0eea33075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "[0 1 2]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(2,dtype=int)\n",
    "b = np.arange(3)\n",
    "print(a)\n",
    "print(b)\n",
    "c = b[a]\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPGCncgH1IYHO+pWHnrU8ea",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
