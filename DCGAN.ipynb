{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6vrpIEg+BaaNwcwWQ7dX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kallviktor/RandomInterpolationGAN/blob/RewriteDCGAN/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C12B_Jtthu2r"
      },
      "source": [
        "https://github.com/kmualim/DCGAN-Keras-Implementation/blob/master/dcgan-mnist.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "phK8FR8Vfwlq",
        "outputId": "e0ed23c1-9105-4e00-e6b7-5d1316c6ce1a"
      },
      "source": [
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Reshape \r\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D \r\n",
        "from keras.layers import LeakyReLU, Dropout \r\n",
        "from keras.layers import BatchNormalization \r\n",
        "from keras.optimizers import Adam, RMSprop\r\n",
        "from keras.initializers import RandomNormal, Zeros\r\n",
        "from keras.datasets import mnist\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import sys \r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class GAN(object): \r\n",
        "    def __init__(self):\r\n",
        "      self.img_rows = 28 \r\n",
        "      self.img_cols = 28 \r\n",
        "      self.channel=1\r\n",
        "      self.img_shape = (self.img_rows, self.img_cols, self.channel)\r\n",
        "      \r\n",
        "      optimizer = Adam(0.0002, 0.5)\r\n",
        "     \r\n",
        "    def build_discriminator(self):\r\n",
        "      model = Sequential()\r\n",
        "      depth = 32 \r\n",
        "      dropout=0.25 \r\n",
        "      input_shape = (self.img_rows, self.img_cols, self.channel)\r\n",
        "      \r\n",
        "      model.add(Conv2D(depth*1, 3, strides=2, input_shape=input_shape, padding='same', kernel_initializer='random_uniform'))\r\n",
        "      model.add(BatchNormalization(momentum=0.9))\r\n",
        "      model.add(LeakyReLU(alpha=0.2))\r\n",
        "      model.add(Dropout(dropout))\r\n",
        "      model.add(Conv2D(depth*2, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\r\n",
        "      model.add(BatchNormalization(momentum=0.9))\r\n",
        "      model.add(LeakyReLU(alpha=0.2))\r\n",
        "      model.add(Dropout(dropout))\r\n",
        "      model.add(Conv2D(depth*4, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\r\n",
        "      model.add(BatchNormalization(momentum=0.9))\r\n",
        "      model.add(LeakyReLU(alpha=0.2))\r\n",
        "      model.add(Dropout(dropout))\r\n",
        "      model.add(Conv2D(depth*8, 3, strides=2, padding='same',kernel_initializer='random_uniform'))\r\n",
        "      model.add(BatchNormalization(momentum=0.9))\r\n",
        "      model.add(LeakyReLU(alpha=0.2))\r\n",
        "      model.add(Dropout(dropout))\r\n",
        "\r\n",
        "      # Each MNIST input = 28 X 28 X 1, depth = 1\r\n",
        "      # Each Output = 14 X 14 X 1, depth = 64 \r\n",
        "      # Model has 4 convolutional layer, each with a dropout layer in between \r\n",
        "\r\n",
        "      # Output \r\n",
        "      model.add(Flatten())\r\n",
        "      model.add(Dense(1))\r\n",
        "      model.add(Activation('sigmoid'))\r\n",
        "      model.summary()\r\n",
        "      \r\n",
        "      img = Input(shape=(self.img_shape))\r\n",
        "      validity = model(img)\r\n",
        "      \r\n",
        "      return Model(img, validity) \r\n",
        "\r\n",
        "    # generator takes noise as input and generates imgs\r\n",
        "                \r\n",
        "    def build_generator(self):\r\n",
        "      generator = Sequential() \r\n",
        "      dropout = 0.4 \r\n",
        "      depth = 128\r\n",
        "      dim = 7\r\n",
        "\r\n",
        "      # In: 100 \r\n",
        "      # Out: dim X dim X depth \r\n",
        "\r\n",
        "      generator.add(Dense(dim*dim*depth, input_dim=100))\r\n",
        "      generator.add(Activation('relu'))\r\n",
        "      generator.add(Reshape((dim, dim, depth)))\r\n",
        "      generator.add(UpSampling2D())\r\n",
        "      #generator.add(Dropout(dropout))\r\n",
        "\r\n",
        "      # In: dim X dim X depth\r\n",
        "      # Out: 2*dim X 2*dim X depth/2 \r\n",
        "\r\n",
        "      generator.add(Conv2D(depth, 3, padding='same'))\r\n",
        "      generator.add(BatchNormalization(momentum=0.9))\r\n",
        "      generator.add(Activation('relu'))\r\n",
        "      generator.add(UpSampling2D())\r\n",
        "      generator.add(Conv2D(int(depth/2), 3, padding='same'))\r\n",
        "      generator.add(BatchNormalization(momentum=0.9))\r\n",
        "      generator.add(Activation('relu'))\r\n",
        "     \r\n",
        "\r\n",
        "      # Out : 28 X 28 X 1 grayscale image [0.0, 1.0] per pix\r\n",
        "      generator.add(Conv2D(1,3,padding='same'))\r\n",
        "      generator.add(Activation('tanh'))\r\n",
        "      generator.summary()\r\n",
        "      \r\n",
        "      noise = Input(shape=(100,))\r\n",
        "      img = generator(noise)\r\n",
        "      \r\n",
        "      return Model(noise, img)\r\n",
        "    \r\n",
        "    # Build and compile discriminator\r\n",
        "    def DM(self):\r\n",
        "      optimizer = Adam(0.0002, 0.5)\r\n",
        "      DM = self.build_discriminator()\r\n",
        "      DM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
        "      return DM    \r\n",
        "\r\n",
        "class dcgan(object):\r\n",
        "  def __init__(self):\r\n",
        "    self.img_rows=28\r\n",
        "    self.img_cols=28\r\n",
        "    self.channels=1\r\n",
        "\r\n",
        "    # building the generator \r\n",
        "    self.GAN = GAN()\r\n",
        "    self.DM = self.GAN.DM()\r\n",
        "    self.generator = self.GAN.build_generator()\r\n",
        "\r\n",
        "\r\n",
        "    z = Input(shape=(100,))\r\n",
        "    img = self.generator(z)\r\n",
        "    self.DM.trainable = False\r\n",
        "    \r\n",
        "    self.combined = Model(z, valid)\r\n",
        "    optimizer = Adam(0.0002, 0.5)\r\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\r\n",
        "    \r\n",
        "    # training input \r\n",
        "    # To change dataset, place dataset below \r\n",
        "    (self.x_train, _), (_,_) = mnist.load_data()\r\n",
        "    self.x_train = self.x_train/127.5 -1.\r\n",
        "    self.x_train = np.expand_dims(self.x_train, axis=3) \r\n",
        "    #x_train = x_train/127.5 -1. \r\n",
        "    #x_train = np.expand_dims(x_train, axis=3)\r\n",
        "    self.n_samples = 25\r\n",
        "    self.noise_dim = 100\r\n",
        "  \r\n",
        "  # method to generate noise \r\n",
        "  def gennoise(self,batch_size, noise_dim): \r\n",
        "   \tx = np.random.normal(0, 1.0, (batch_size, self.noise_dim))\r\n",
        "   \treturn x\r\n",
        "\r\n",
        "  def plt_imgs(self,epoch): \r\n",
        "    noise = self.gennoise(self.n_samples, self.noise_dim)\r\n",
        "    print(noise)\r\n",
        "    print(noise.shape)\r\n",
        "    fake_imgs = self.generator.predict(noise)\r\n",
        "    print(fake_imgs.shape)\r\n",
        "    fake_imgs = 0.5 * fake_imgs + 0.5\r\n",
        "  \r\n",
        "    fig,axs = plt.subplots(5,5)\r\n",
        "    count = 0 \r\n",
        "    for i in range(5): \r\n",
        "        for j in range(5): \r\n",
        "          axs[i,j].imshow(fake_imgs[count, :, :, 0], cmap='gray')\r\n",
        "          axs[i,j].axis('off')\r\n",
        "          count+=1\r\n",
        "      \r\n",
        "    fig.savefig(\"mnist_%d.png\" % epoch)\r\n",
        "    plt.close()\r\n",
        "  \r\n",
        "  \r\n",
        "  def train(self,n_epochs, batch_size):\r\n",
        "    train_hist={}\r\n",
        "    train_hist['D_losses']=[]\r\n",
        "    train_hist['G_losses']=[]\r\n",
        "    print(\"Start\")\r\n",
        "    true_labels=np.ones((batch_size,1))\r\n",
        "    gen_gene_labels=np.zeros((batch_size,1))\r\n",
        "    \r\n",
        "    for epoch in range(n_epochs):\r\n",
        "    \r\n",
        "      index = np.random.randint(0, self.x_train.shape[0], batch_size)\r\n",
        "      images = self.x_train[index]\r\n",
        "      \r\n",
        "      noise_data = self.gennoise(batch_size, 100)\r\n",
        "      gen_imgs = self.generator.predict(noise_data)\r\n",
        "      \r\n",
        "      \r\n",
        "      d_loss = self.DM.train_on_batch(images, true_labels)\r\n",
        "    \r\n",
        "      d_loss_generated = self.DM.train_on_batch(gen_imgs, gen_gene_labels)\r\n",
        "      \r\n",
        "      total_d_loss = 0.5 * np.add(d_loss, d_loss_generated)\r\n",
        "      \r\n",
        "      train_hist['D_losses'].append(total_d_loss[0])\r\n",
        "        \r\n",
        "      noise_data = self.gennoise(batch_size, 100)\r\n",
        "      y1 = np.ones((batch_size, 1))    \r\n",
        "      \r\n",
        "      g_loss = self.combined.train_on_batch(noise_data, y1)\r\n",
        "\r\n",
        "      train_hist['G_losses'].append(g_loss)\r\n",
        "      print (' Epoch:{}, G_loss: {}, D_loss:{}'.format(epoch+1, g_loss, total_d_loss[0]))\r\n",
        "      \r\n",
        "      #if epoch%50==0:\r\n",
        "      if epoch%2 == 0:\r\n",
        "        self.plt_imgs(epoch)\r\n",
        "      \r\n",
        "    return train_hist\r\n",
        "\r\n",
        "#if __name__ == '__main__': \r\n",
        "mnist_dcgan = dcgan()\r\n",
        "train_hist = mnist_dcgan.train(10, batch_size=32)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1025      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 390,785\n",
            "Trainable params: 389,825\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 1)         577       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 856,193\n",
            "Trainable params: 855,809\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-d6300aefc1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;31m#if __name__ == '__main__':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m \u001b[0mmnist_dcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0mtrain_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_dcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-d6300aefc1b8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hutkmn9C9byL",
        "outputId": "ca8f6923-92d2-40a9-b71f-c9a9f0b30f20"
      },
      "source": [
        "z = mnist_dcgan.gennoise(1,100)\r\n",
        "#z.shape\r\n",
        "x = mnist_dcgan.generator.predict(z)\r\n",
        "x.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}